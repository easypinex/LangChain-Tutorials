{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "MAP_SYSTEM_PROMPT = \"\"\"\n",
    "---Role---\n",
    "\n",
    "You are a helpful assistant responding to questions about data in the tables provided.\n",
    "\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response consisting of a list of key points that responds to the user's question, summarizing all relevant information in the input data tables.\n",
    "\n",
    "You should use the data provided in the data tables below as the primary context for generating the response.\n",
    "If you don't know the answer or if the input data tables do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "Each key point in the response should have the following element:\n",
    "- Description: A comprehensive description of the point.\n",
    "- Importance Score: An integer score between 0-100 that indicates how important the point is in answering the user's question. An 'I don't know' type of response should have a score of 0.\n",
    "\n",
    "The response should be JSON formatted as follows:\n",
    "{{\n",
    "    \"points\": [\n",
    "        {{\"description\": \"Description of point 1 [Data: Reports (report ids)]\", \"score\": score_value}},\n",
    "        {{\"description\": \"Description of point 2 [Data: Reports (report ids)]\", \"score\": score_value}}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "Points supported by data should list the relevant reports as references as follows:\n",
    "\"This is an example sentence supported by data references [Data: Reports (report ids)]\"\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 64, 46, 34, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data report in the provided tables.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "\n",
    "---Data tables---\n",
    "\n",
    "{context_data}\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response consisting of a list of key points that responds to the user's question, summarizing all relevant information in the input data tables.\n",
    "\n",
    "You should use the data provided in the data tables below as the primary context for generating the response.\n",
    "If you don't know the answer or if the input data tables do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "Each key point in the response should have the following element:\n",
    "- Description: A comprehensive description of the point.\n",
    "- Importance Score: An integer score between 0-100 that indicates how important the point is in answering the user's question. An 'I don't know' type of response should have a score of 0.\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "Points supported by data should list the relevant reports as references as follows:\n",
    "\"This is an example sentence supported by data references [Data: Reports (report ids)]\"\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 64, 46, 34, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data report in the provided tables.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "The response should be JSON formatted as follows:\n",
    "{{\n",
    "    \"points\": [\n",
    "        {{\"description\": \"Description of point 1 [Data: Reports (report ids)]\", \"score\": score_value}},\n",
    "        {{\"description\": \"Description of point 2 [Data: Reports (report ids)]\", \"score\": score_value}}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            MAP_SYSTEM_PROMPT,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "map_chain = map_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCE_SYSTEM_PROMPT = \"\"\"\n",
    "---Role---\n",
    "\n",
    "You are a helpful assistant responding to questions about a dataset by synthesizing perspectives from multiple analysts.\n",
    "\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response of the target length and format that responds to the user's question, summarize all the reports from multiple analysts who focused on different parts of the dataset.\n",
    "\n",
    "Note that the analysts' reports provided below are ranked in the **descending order of importance**.\n",
    "\n",
    "If you don't know the answer or if the provided reports do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "The final response should remove all irrelevant information from the analysts' reports and merge the cleaned information into a comprehensive answer that provides explanations of all the key points and implications appropriate for the response length and format.\n",
    "\n",
    "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "The response should also preserve all the data references previously included in the analysts' reports, but do not mention the roles of multiple analysts in the analysis process.\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 34, 46, 64, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "\n",
    "---Target response length and format---\n",
    "\n",
    "{response_type}\n",
    "\n",
    "\n",
    "---Analyst Reports---\n",
    "\n",
    "{report_data}\n",
    "\n",
    "\n",
    "---Goal---\n",
    "\n",
    "Generate a response of the target length and format that responds to the user's question, summarize all the reports from multiple analysts who focused on different parts of the dataset.\n",
    "\n",
    "Note that the analysts' reports provided below are ranked in the **descending order of importance**.\n",
    "\n",
    "If you don't know the answer or if the provided reports do not contain sufficient information to provide an answer, just say so. Do not make anything up.\n",
    "\n",
    "The final response should remove all irrelevant information from the analysts' reports and merge the cleaned information into a comprehensive answer that provides explanations of all the key points and implications appropriate for the response length and format.\n",
    "\n",
    "The response shall preserve the original meaning and use of modal verbs such as \"shall\", \"may\" or \"will\".\n",
    "\n",
    "The response should also preserve all the data references previously included in the analysts' reports, but do not mention the roles of multiple analysts in the analysis process.\n",
    "\n",
    "**Do not list more than 5 record ids in a single reference**. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
    "\n",
    "For example:\n",
    "\n",
    "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (2, 7, 34, 46, 64, +more)]. He is also CEO of company X [Data: Reports (1, 3)]\"\n",
    "\n",
    "where 1, 2, 3, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "\n",
    "---Target response length and format---\n",
    "\n",
    "{response_type}\n",
    "\n",
    "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            REDUCE_SYSTEM_PROMPT,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "reduce_chain = reduce_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"2wsx3edc\"\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "response_type: str = \"multiple paragraphs\"\n",
    "def global_retriever(query: str, level: int, response_type: str = response_type) -> str:\n",
    "    community_data = graph.query(\n",
    "        \"\"\"\n",
    "    MATCH (c:__Community__)\n",
    "    WHERE c.level = $level\n",
    "    RETURN c.summary AS output\n",
    "    \"\"\",\n",
    "        params={\"level\": level},\n",
    "    )\n",
    "    intermediate_results = []\n",
    "    for community in tqdm(community_data, desc=\"Processing communities\"):\n",
    "        intermediate_response = map_chain.invoke(\n",
    "            {\"question\": query, \"context_data\": community[\"output\"]}\n",
    "        )\n",
    "        intermediate_results.append(intermediate_response)\n",
    "    final_response = reduce_chain.invoke(\n",
    "        {\n",
    "            \"report_data\": intermediate_results,\n",
    "            \"question\": query,\n",
    "            \"response_type\": response_type,\n",
    "        }\n",
    "    )\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing communities: 100%|██████████| 7/7 [00:13<00:00,  1.88s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### 台灣人壽是什麼?\\n\\n台灣人壽是一家保險公司，負責提供各類保險服務。在這些服務中，包括增值回饋分享金的提供和宣告利率的計算 [Data: Reports (1, 2, 3, 4, 5)]。增值回饋分享金是指台灣人壽將某些收益返還給要保人，這些收益會根據特定的宣告利率進行計算 [Data: Reports (1, 2, 3, 4, 5)]。\\n\\n此外，台灣人壽還負責處理這些增值回饋分享金，並將其返還給要保人 [Data: Reports (1, 2, 3, 4, 5)]。要保人也可以選擇和台灣人壽終止合同，這意味著他們可以在特定的條件下取消保單 [Data: Reports (1, 2, 3, 4, 5)]。\\n\\n### 綜合分析\\n\\n台灣人壽的運作機制及其提供的服務，尤其是增值回饋分享金的安排，顯示出這家公司在保險市場中具有一定的靈活性和回饋機制。要保人不僅可以享受保險服務，還可以在某些情況下獲得額外的回饋，這對於提高客戶滿意度和忠誠度有著重要意義。\\n\\n總結來說，台灣人壽透過多樣化的保險產品和增值服務，為要保人提供了多種選擇和利益，這使得它在保險市場中具有競爭力。'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_retriever('台灣人壽是什麼?', 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lagch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
