{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref: https://medium.com/neo4j/implementing-from-local-to-global-graphrag-with-neo4j-and-langchain-constructing-the-graph-73924cc5bab4\n",
    "### Ref(Github): https://github.com/tomasonjo/blogs/blob/master/llm/ms_graphrag.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"2wsx3edc\"\n",
    "\n",
    "database = os.environ.get('NEO4J_DATABASE')\n",
    "graph = Neo4jGraph(database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    azure_endpoint='https://sales-chatbot-llm.openai.azure.com/openai/deployments/embedding-ada-002/embeddings?api-version=2023-05-15',\n",
    "    azure_deployment='text-embedding-ada-002',\n",
    "    openai_api_version='2023-05-15'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "# ! pip3 install -U langchain-huggingface\n",
    "import os\n",
    "os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/storage/models/embedding_models'\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# Choose from https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "# embedding = HuggingFaceEmbeddings(model_name=\"lier007/xiaobu-embedding-v2\")\n",
    "\n",
    "model_path = os.path.join(os.environ['SENTENCE_TRANSFORMERS_HOME'], 'models--lier007--xiaobu-embedding-v2/snapshots/ee0b4ecdf5eb449e8240f2e3de2e10eeae877691')\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "789"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_label = '__Entity__'\n",
    "embedding_node_property = 'embedding'\n",
    "fetch_query = (\n",
    "    f\"MATCH (n:`{node_label}`) \"\n",
    "    f\"WHERE n.{embedding_node_property} IS null \"\n",
    "    \"AND any(k in $props WHERE n[k] IS NOT null) \"\n",
    "    f\"RETURN elementId(n) AS id, reduce(str='',\"\n",
    "    \"k IN $props | str + '\\\\n' + k + ':' + coalesce(n[k], '')) AS text \"\n",
    "    \"LIMIT 1000\"\n",
    ")\n",
    "datas = graph.query(fetch_query, params={\"props\": ['id', 'description']})\n",
    "datas\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from tools.TokenCounter import num_tokens_from_string\n",
    "\n",
    "tokens_num = 0\n",
    "for data in datas:\n",
    "    tokens_num += num_tokens_from_string(data['text'])\n",
    "tokens_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Neo4jVector.from_existing_graph(\n",
    "    embedding,\n",
    "    index_name='embedding',\n",
    "    node_label='__Entity__',\n",
    "    text_node_properties=['id', 'description'],\n",
    "    embedding_node_property='embedding'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install graphdatascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience \n",
    "\n",
    "gds = GraphDataScience( \n",
    "    os.environ[ \"NEO4J_URI\" ], \n",
    "    auth=(os.environ[ \"NEO4J_USERNAME\" ], os.environ[ \"NEO4J_PASSWORD\" ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graphName                                                         entities\n",
       "database                                                             neo4j\n",
       "databaseLocation                                                     local\n",
       "memoryUsage                                                               \n",
       "sizeInBytes                                                             -1\n",
       "nodeCount                                                               25\n",
       "relationshipCount                                                       85\n",
       "configuration            {'relationshipProjection': {'__ALL__': {'aggre...\n",
       "density                                                           0.141667\n",
       "creationTime                           2024-09-09T04:45:12.577411763+00:00\n",
       "modificationTime                       2024-09-09T04:45:13.928689638+00:00\n",
       "schema                   {'graphProperties': {}, 'nodes': {'__Entity__'...\n",
       "schemaWithOrientation    {'graphProperties': {}, 'nodes': {'__Entity__'...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.graph.drop(\"entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G, result = gds.graph.project(\n",
    "    \"entities\",                   # Graph name\n",
    "    \"__Entity__\",                 # Node projection\n",
    "    \"*\",                          # Relationship projection\n",
    "    nodeProperties=[\"embedding\"]  # Configuration parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ranIterations                                                             3\n",
       "nodePairsConsidered                                                    6519\n",
       "didConverge                                                            True\n",
       "preProcessingMillis                                                       0\n",
       "computeMillis                                                            24\n",
       "mutateMillis                                                             11\n",
       "postProcessingMillis                                                      0\n",
       "nodesCompared                                                            26\n",
       "relationshipsWritten                                                     54\n",
       "similarityDistribution    {'min': 0.9500160217285156, 'p5': 0.9503250122...\n",
       "configuration             {'mutateProperty': 'score', 'jobId': 'de751ef3...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_threshold = 0.95\n",
    "\n",
    "gds.knn.mutate(\n",
    "  G,\n",
    "  nodeProperties=['embedding'],\n",
    "  mutateRelationshipType= 'SIMILAR',\n",
    "  mutateProperty= 'score',\n",
    "  similarityCutoff=similarity_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "writeMillis                                                             46\n",
       "nodePropertiesWritten                                                   26\n",
       "componentCount                                                           8\n",
       "componentDistribution    {'min': 1, 'p5': 1, 'max': 7, 'p999': 7, 'p99'...\n",
       "postProcessingMillis                                                    11\n",
       "preProcessingMillis                                                      0\n",
       "computeMillis                                                            1\n",
       "configuration            {'writeProperty': 'wcc', 'jobId': 'd95c8b7f-bd...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.wcc.write(\n",
    "    G,\n",
    "    writeProperty=\"wcc\",\n",
    "    relationshipTypes=[\"SIMILAR\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_edit_distance = 3\n",
    "potential_duplicate_candidates = graph.query(\n",
    "    \"\"\"MATCH (e:`__Entity__`)\n",
    "    WHERE size(e.id) > 3 // longer than 3 characters\n",
    "    WITH e.wcc AS community, collect(e) AS nodes, count(*) AS count\n",
    "    WHERE count > 1\n",
    "    UNWIND nodes AS node\n",
    "    // Add text distance\n",
    "    WITH distinct\n",
    "      [n IN nodes WHERE apoc.text.distance(toLower(node.id), toLower(n.id)) < $distance \n",
    "                  OR node.id CONTAINS n.id | n.id] AS intermediate_results\n",
    "    WHERE size(intermediate_results) > 1\n",
    "    WITH collect(intermediate_results) AS results\n",
    "    // combine groups together if they share elements\n",
    "    UNWIND range(0, size(results)-1, 1) as index\n",
    "    WITH results, index, results[index] as result\n",
    "    WITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |\n",
    "            CASE WHEN index <> index2 AND\n",
    "                size(apoc.coll.intersection(acc, results[index2])) > 0\n",
    "                THEN apoc.coll.union(acc, results[index2])\n",
    "                ELSE acc\n",
    "            END\n",
    "    )) as combinedResult\n",
    "    WITH distinct(combinedResult) as combinedResult\n",
    "    // extra filtering\n",
    "    WITH collect(combinedResult) as allCombinedResults\n",
    "    UNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex\n",
    "    WITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults\n",
    "    WHERE NOT any(x IN range(0,size(allCombinedResults)-1,1)\n",
    "        WHERE x <> combinedResultIndex\n",
    "        AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)\n",
    "    )\n",
    "    RETURN combinedResult\n",
    "    \"\"\", params={'distance': word_edit_distance})\n",
    "potential_duplicate_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/miniforge3/envs/lagch/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `OllamaFunctions` was deprecated in LangChain 0.0.64 and will be removed in 0.4.0. An updated version of the class exists in the langchain-ollama package and should be used instead. To use it run `pip install -U langchain-ollama` and import as `from langchain_ollama import ChatOllama`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OllamaFunctions(model='qwen2:72b-instruct-q8_0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "model_name = 'qwen2:72b-instruct-q8_0'\n",
    "llm = OllamaFunctions(model=model_name, temperature=0)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"You are a data processing assistant. Your task is to identify duplicate entities in a list and decide which of them should be merged.\n",
    "The entities might be slightly different in format or content, but essentially refer to the same thing. Use your analytical skills to determine duplicates.\n",
    "\n",
    "Here are the rules for identifying duplicates:\n",
    "1. Entities with minor typographical differences should be considered duplicates.\n",
    "2. Entities with different formats but the same content should be considered duplicates.\n",
    "3. Entities that refer to the same real-world object or concept, even if described differently, should be considered duplicates.\n",
    "4. If it refers to different numbers, dates, or products, do not merge results\n",
    "\"\"\"\n",
    "user_template = \"\"\"\n",
    "Here is the list of entities to process:\n",
    "{entities}\n",
    "\n",
    "Please identify duplicates, merge them, and provide the merged list.\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DuplicateEntities(BaseModel):\n",
    "    entities: List[str] = Field(\n",
    "        description=\"Entities that represent the same object or real-world entity and should be merged\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Disambiguate(BaseModel):\n",
    "    merge_entities: Optional[List[DuplicateEntities]] = Field(\n",
    "        description=\"Lists of entities that represent the same object or real-world entity and should be merged\"\n",
    "    )\n",
    "\n",
    "\n",
    "extraction_llm = llm.with_structured_output(\n",
    "    Disambiguate\n",
    ")\n",
    "\n",
    "extraction_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            user_template,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = extraction_prompt | extraction_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def resolve_and_merge_entities_with_llm(potential_duplicate_candidates, max_retry=0) -> List[List[str]]:\n",
    "    '''\n",
    "    parmas:\n",
    "        potential_duplicate_candidates(List[dict['combinedResult': List[str]]): 有可能需要合併的清單 \n",
    "                                                                                e.g.[{'combinedResult': ['土地銀行', '第一銀行']}]\n",
    "        max_retry: 最多嘗試次數, 假設為2, 則最多遞迴執行 2+1=3次\n",
    "    return:\n",
    "        merged_entities (List[dict['combinedResult': List[str]]) : LLM 確認過需要合併的清單\n",
    "                                                                    e.g.[{'combinedResult': ['土地銀行', '第一銀行']}]\n",
    "    '''\n",
    "    def entity_resolution(entities: List[str]) -> Optional[List[List[str]]]:\n",
    "        return [\n",
    "            el.entities\n",
    "            for el in extraction_chain.invoke({\"entities\": entities}).merge_entities\n",
    "        ]\n",
    "        \n",
    "    merged_entities_result = []\n",
    "    merged_future_map = {}\n",
    "    futures = []\n",
    "    merged_failds = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submitting all tasks and creating a list of future objects\n",
    "        for el in potential_duplicate_candidates:\n",
    "            future = executor.submit(entity_resolution, el['combinedResult'])\n",
    "            merged_future_map[future] = el\n",
    "            futures.append(future)\n",
    "        for future in tqdm(\n",
    "            as_completed(futures), total=len(futures), desc=\"Processing documents\"\n",
    "        ):\n",
    "            try:\n",
    "                to_merge = future.result()\n",
    "                if to_merge:\n",
    "                    merged_entities_result.extend(to_merge)\n",
    "            except Exception as e:\n",
    "                el = merged_future_map[future]\n",
    "                print(f'process element faild!:{el['combinedResult']}, error:\\n{e}')\n",
    "                merged_failds.append(el)\n",
    "    if len(merged_failds) > 0 and max_retry > 0:\n",
    "        merged_entities_result.extend(resolve_and_merge_entities_with_llm(merged_failds, max_retry=max_retry-1))\n",
    "    return merged_entities_result\n",
    "merged_entities = resolve_and_merge_entities_with_llm(potential_duplicate_candidates, max_retry=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "for merge_entity in merged_entities:\n",
    "    merge_entities = [merge_entity]\n",
    "    results = graph.query(\"\"\"\n",
    "  UNWIND $data AS candidates\n",
    "  CALL {\n",
    "    WITH candidates\n",
    "    MATCH (e:__Entity__) WHERE e.id IN candidates\n",
    "    RETURN collect(e) AS nodes\n",
    "  }\n",
    "  CALL apoc.refactor.mergeNodes(nodes, {\n",
    "      properties: {\n",
    "        description: 'combine',\n",
    "        `.*`: 'discard'\n",
    "      }\n",
    "    })\n",
    "  YIELD node\n",
    "  RETURN count(*)\n",
    "  \"\"\", params={\"data\": merge_entities})\n",
    "    count += results[0]['count(*)']\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
