{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref: https://medium.com/neo4j/implementing-from-local-to-global-graphrag-with-neo4j-and-langchain-constructing-the-graph-73924cc5bab4\n",
    "### Ref(Github): https://github.com/tomasonjo/blogs/blob/master/llm/ms_graphrag.ipynb"
   ]openai_api_version=os.environ["AZURE_OPENAI_API_VERSION"]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"2wsx3edc\"\n",
    "\n",
    "database = os.environ.get('NEO4J_DATABASE')\n",
    "graph = Neo4jGraph(database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment='text-embedding-3-small',\n",
    "    openai_api_version='2023-05-15'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.vectorstores import Neo4jVector\n",
    "# # ! pip3 install -U langchain-huggingface\n",
    "# import os\n",
    "# os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/storage/models/embedding_models'\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# # Choose from https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "# # embedding = HuggingFaceEmbeddings(model_name=\"lier007/xiaobu-embedding-v2\")\n",
    "\n",
    "# model_path = os.path.join(os.environ['SENTENCE_TRANSFORMERS_HOME'], 'models--lier007--xiaobu-embedding-v2/snapshots/ee0b4ecdf5eb449e8240f2e3de2e10eeae877691')\n",
    "# embedding = HuggingFaceEmbeddings(model_name=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_label = '__Entity__'\n",
    "# embedding_node_property = 'embedding'\n",
    "# fetch_query = (\n",
    "#     f\"MATCH (n:`{node_label}`) \"\n",
    "#     f\"WHERE n.{embedding_node_property} IS null \"\n",
    "#     \"AND any(k in $props WHERE n[k] IS NOT null) \"\n",
    "#     f\"RETURN elementId(n) AS id, reduce(str='',\"\n",
    "#     \"k IN $props | str + '\\\\n' + k + ':' + coalesce(n[k], '')) AS text \"\n",
    "#     \"LIMIT 1000\"\n",
    "# )\n",
    "# datas = graph.query(fetch_query, params={\"props\": ['id', 'description']})\n",
    "# datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('..')\n",
    "# from tools.TokenCounter import num_tokens_from_string\n",
    "\n",
    "# tokens_num = 0\n",
    "# for data in datas:\n",
    "#     tokens_num += num_tokens_from_string(data['text'])\n",
    "# tokens_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Neo4jVector.from_existing_graph(\n",
    "    embedding,\n",
    "    index_name='embedding',\n",
    "    node_label='__Entity__',\n",
    "    text_node_properties=['id', 'description'],\n",
    "    embedding_node_property='embedding'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install graphdatascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience \n",
    "\n",
    "gds = GraphDataScience( \n",
    "    os.environ[ \"NEO4J_URI\" ], \n",
    "    auth=(os.environ[ \"NEO4J_USERNAME\" ], os.environ[ \"NEO4J_PASSWORD\" ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.graph.drop(\"entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G, result = gds.graph.project(\n",
    "    \"entities\",                   # Graph name\n",
    "    \"__Entity__\",                 # Node projection\n",
    "    \"*\",                          # Relationship projection\n",
    "    nodeProperties=[\"embedding\"]  # Configuration parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ranIterations                                                             7\n",
       "nodePairsConsidered                                                  230078\n",
       "didConverge                                                            True\n",
       "preProcessingMillis                                                       2\n",
       "computeMillis                                                           368\n",
       "mutateMillis                                                             65\n",
       "postProcessingMillis                                                      0\n",
       "nodesCompared                                                           578\n",
       "relationshipsWritten                                                    144\n",
       "similarityDistribution    {'min': 0.9500541687011719, 'p5': 0.9516181945...\n",
       "configuration             {'mutateProperty': 'score', 'jobId': 'd608edde...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 gds.knn.mutate 根據嵌入向量相似度創建關聯關係\n",
    "\n",
    "similarity_threshold = 0.95\n",
    "\n",
    "gds.knn.mutate(\n",
    "  G,\n",
    "  nodeProperties=['embedding'],\n",
    "  mutateRelationshipType= 'SIMILAR',\n",
    "  mutateProperty= 'score',\n",
    "  similarityCutoff=similarity_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "writeMillis                                                             54\n",
       "nodePropertiesWritten                                                  578\n",
       "componentCount                                                         515\n",
       "componentDistribution    {'min': 1, 'p5': 1, 'max': 4, 'p999': 4, 'p99'...\n",
       "postProcessingMillis                                                     5\n",
       "preProcessingMillis                                                      0\n",
       "computeMillis                                                            4\n",
       "configuration            {'writeProperty': 'wcc', 'jobId': 'bd78d42f-d1...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 gds.wcc.write 將相似節點進行社群劃分\n",
    "# writeProperty=\"wcc\": 為每個節點寫入 wcc 屬性，表示該節點屬於哪個社群。\n",
    "\n",
    "gds.wcc.write(\n",
    "    G,\n",
    "    writeProperty=\"wcc\",\n",
    "    relationshipTypes=[\"SIMILAR\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'combinedResult': ['住院醫療費用保險金限額', '住院醫療費用保險金限額_2']},\n",
       " {'combinedResult': ['每日住院病房費用保險金限額', '每日住院病房費用保險金限額_2']},\n",
       " {'combinedResult': ['門診外科手術治療', '門診手術', '門診手術治療', '門診治療']},\n",
       " {'combinedResult': ['投保計劃', '投保計劃別']},\n",
       " {'combinedResult': ['第十三條', '第十二條', '第十四條']},\n",
       " {'combinedResult': ['子宮頸未全開', '子宮頸未全開而有臍帶脫落', '子宮頸未全開而有臍帶脫落時']},\n",
       " {'combinedResult': ['早期破水', '早期破水超過24小時合併感染現象']},\n",
       " {'combinedResult': ['嚴重心律不整', '心律不整']},\n",
       " {'combinedResult': ['因醫療行為所必要之流產', '醫療行為所必要之流產']},\n",
       " {'combinedResult': ['第十七條', '第十六條']},\n",
       " {'combinedResult': ['胎兒頭皮酸鹼度檢查', '胎兒頭皮酸鹼度檢查Ph值少於7.20']},\n",
       " {'combinedResult': ['第二十六條', '第二十四條']},\n",
       " {'combinedResult': ['異體周邊造血細胞移植', '自體周邊造血細胞移植']},\n",
       " {'combinedResult': ['胃靜脈瘤硬化治療', '食道靜脈瘤硬化治療']},\n",
       " {'combinedResult': ['經皮冠狀動脈擴張術－一條血管', '經皮冠狀動脈擴張術－三條血管', '經皮冠狀動脈擴張術－二條血管']},\n",
       " {'combinedResult': ['囊腫摘除術(中)', '囊腫摘除術(大)', '囊腫摘除術(小)']},\n",
       " {'combinedResult': ['硬組織切片', '軟組織切片']},\n",
       " {'combinedResult': ['腐骨清除術－簡單', '腐骨清除術－複雜']},\n",
       " {'combinedResult': ['住院日數三十一至六十日', '住院日數六十一至九十日']},\n",
       " {'combinedResult': ['住院前後門診費用保險金限額', '住院前後門診費用保險金限額_2']},\n",
       " {'combinedResult': ['外科手術費用保險金限額', '外科手術費用保險金限額_2']},\n",
       " {'combinedResult': ['出院後門診腫瘤治療費用保險金限額', '出院後門診腫瘤治療費用保險金限額_2']},\n",
       " {'combinedResult': ['補充保險金限額', '補充保險金限額_2']},\n",
       " {'combinedResult': ['胸腔成形術(第一期)', '胸腔成形術(第三期)', '胸腔成形術(第二期)']},\n",
       " {'combinedResult': ['肺全切除術', '肺單元切除術']},\n",
       " {'combinedResult': ['食道切除再造術', '食道切除術']},\n",
       " {'combinedResult': ['次全或半胃切除術(有迷走神經切除)', '次全或半胃切除術(無迷走神經切除)']},\n",
       " {'combinedResult': ['肝臟手術', '胰臟手術']},\n",
       " {'combinedResult': ['肝區域切除術(一區域)', '肝區域切除術(三區域)', '肝區域切除術(二區域)']},\n",
       " {'combinedResult': ['膀胱全部切除(有人造膀胱)', '膀胱全部切除(無人造膀胱)']},\n",
       " {'combinedResult': ['尿失禁手術(經腹)', '尿失禁手術(經陰道)']},\n",
       " {'combinedResult': ['單純乳房切除術(單側)', '單純乳房切除術(雙側)']},\n",
       " {'combinedResult': ['乳癌根治切除術(單側)', '乳癌根治切除術(雙側)']},\n",
       " {'combinedResult': ['照射治療規劃及劑量', '照射治療規劃及劑量（每次）']},\n",
       " {'combinedResult': ['直線加速器照射治療', '直線加速器照射治療（每次）']},\n",
       " {'combinedResult': ['椎間盤切除術(胸椎)', '椎間盤切除術(腰椎)', '椎間盤切除術(頸椎)']},\n",
       " {'combinedResult': ['胸交感神經切斷術', '腰交感神經切斷術', '頸交感神經切斷術']}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查找具有潛在重複 ID 的節點\n",
    "word_edit_distance = 3\n",
    "potential_duplicate_candidates = graph.query(\n",
    "    \"\"\"MATCH (e:`__Entity__`)\n",
    "    WHERE size(e.id) > 3 // longer than 3 characters\n",
    "    WITH e.wcc AS community, collect(e) AS nodes, count(*) AS count\n",
    "    WHERE count > 1\n",
    "    UNWIND nodes AS node\n",
    "    // Add text distance\n",
    "    WITH distinct\n",
    "      [n IN nodes WHERE apoc.text.distance(toLower(node.id), toLower(n.id)) < $distance \n",
    "                  OR node.id CONTAINS n.id | n.id] AS intermediate_results\n",
    "    WHERE size(intermediate_results) > 1\n",
    "    WITH collect(intermediate_results) AS results\n",
    "    // combine groups together if they share elements\n",
    "    UNWIND range(0, size(results)-1, 1) as index\n",
    "    WITH results, index, results[index] as result\n",
    "    WITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |\n",
    "            CASE WHEN index <> index2 AND\n",
    "                size(apoc.coll.intersection(acc, results[index2])) > 0\n",
    "                THEN apoc.coll.union(acc, results[index2])\n",
    "                ELSE acc\n",
    "            END\n",
    "    )) as combinedResult\n",
    "    WITH distinct(combinedResult) as combinedResult\n",
    "    // extra filtering\n",
    "    WITH collect(combinedResult) as allCombinedResults\n",
    "    UNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex\n",
    "    WITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults\n",
    "    WHERE NOT any(x IN range(0,size(allCombinedResults)-1,1)\n",
    "        WHERE x <> combinedResultIndex\n",
    "        AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)\n",
    "    )\n",
    "    RETURN combinedResult\n",
    "    \"\"\", params={'distance': word_edit_distance})\n",
    "potential_duplicate_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('potential_duplicate_candidates.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(potential_duplicate_candidates, file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "# model_name = 'qwen2:72b-instruct-q8_0'\n",
    "# llm = OllamaFunctions(model=model_name, temperature=0)\n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"You are a data processing assistant. Your task is to identify duplicate entities in a list and decide which of them should be merged.\n",
    "The entities might be slightly different in format or content, but essentially refer to the same thing. Use your analytical skills to determine duplicates.\n",
    "\n",
    "Here are the rules for identifying duplicates:\n",
    "1. Entities with minor typographical differences should be considered duplicates, except when they refer to differences such as \"new\" vs. \"old,\" or \"initial\" vs. \"renewal.\" In these cases, do not merge the results.\n",
    "2. Entities with different formats but the same content should be considered duplicates.\n",
    "3. Entities that refer to the same real-world object or concept, even if described differently, should be considered duplicates.\n",
    "4. If it refers to different numbers, dates, or products, do not merge results\n",
    "\"\"\"\n",
    "user_template = \"\"\"\n",
    "Here is the list of entities to process:\n",
    "{entities}\n",
    "\n",
    "Please identify duplicates, merge them, and provide the merged list.\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DuplicateEntities(BaseModel):\n",
    "    entities: List[str] = Field(\n",
    "        description=\"Entities that represent the same object or real-world entity and should be merged\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Disambiguate(BaseModel):\n",
    "    merge_entities: Optional[List[DuplicateEntities]] = Field(\n",
    "        description=\"Lists of entities that represent the same object or real-world entity and should be merged\"\n",
    "    )\n",
    "\n",
    "\n",
    "extraction_llm = llm.with_structured_output(\n",
    "    Disambiguate\n",
    ")\n",
    "\n",
    "extraction_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            user_template,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = extraction_prompt | extraction_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   5%|▌         | 2/37 [00:00<00:11,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['第十三條', '第十二條', '第十四條'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  16%|█▌        | 6/37 [00:01<00:04,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['早期破水', '早期破水超過24小時合併感染現象'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  27%|██▋       | 10/37 [00:01<00:02,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['第十七條', '第十六條'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  32%|███▏      | 12/37 [00:02<00:04,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['經皮冠狀動脈擴張術－一條血管', '經皮冠狀動脈擴張術－三條血管', '經皮冠狀動脈擴張術－二條血管'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  43%|████▎     | 16/37 [00:02<00:02,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['囊腫摘除術(中)', '囊腫摘除術(大)', '囊腫摘除術(小)'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['硬組織切片', '軟組織切片'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['腐骨清除術－簡單', '腐骨清除術－複雜'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  49%|████▊     | 18/37 [00:02<00:02,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['第二十六條', '第二十四條'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['住院日數三十一至六十日', '住院日數六十一至九十日'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  51%|█████▏    | 19/37 [00:03<00:03,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['異體周邊造血細胞移植', '自體周邊造血細胞移植'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  65%|██████▍   | 24/37 [00:03<00:01,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['胸腔成形術(第一期)', '胸腔成形術(第三期)', '胸腔成形術(第二期)'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['肺全切除術', '肺單元切除術'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  76%|███████▌  | 28/37 [00:04<00:00,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['次全或半胃切除術(有迷走神經切除)', '次全或半胃切除術(無迷走神經切除)'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['肝臟手術', '胰臟手術'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  86%|████████▋ | 32/37 [00:04<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['膀胱全部切除(有人造膀胱)', '膀胱全部切除(無人造膀胱)'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['肝區域切除術(一區域)', '肝區域切除術(三區域)', '肝區域切除術(二區域)'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['尿失禁手術(經腹)', '尿失禁手術(經陰道)'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['單純乳房切除術(單側)', '單純乳房切除術(雙側)'], error:\n",
      "'NoneType' object is not iterable\n",
      "process element faild!:['乳癌根治切除術(單側)', '乳癌根治切除術(雙側)'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  92%|█████████▏| 34/37 [00:04<00:00,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['椎間盤切除術(胸椎)', '椎間盤切除術(腰椎)', '椎間盤切除術(頸椎)'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 37/37 [00:05<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process element faild!:['胸交感神經切斷術', '腰交感神經切斷術', '頸交感神經切斷術'], error:\n",
      "'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def resolve_and_merge_entities_with_llm(potential_duplicate_candidates, max_retry=0) -> List[List[str]]:\n",
    "    '''\n",
    "    parmas:\n",
    "        potential_duplicate_candidates(List[dict['combinedResult': List[str]]): 有可能需要合併的清單 \n",
    "                                                                                e.g.[{'combinedResult': ['土地銀行', '第一銀行']}]\n",
    "        max_retry: 最多嘗試次數, 假設為2, 則最多遞迴執行 2+1=3次\n",
    "    return:\n",
    "        merged_entities (List[dict['combinedResult': List[str]]) : LLM 確認過需要合併的清單\n",
    "                                                                    e.g.[{'combinedResult': ['土地銀行', '第一銀行']}]\n",
    "    '''\n",
    "    def entity_resolution(entities: List[str]) -> Optional[List[List[str]]]:\n",
    "        return [\n",
    "            el.entities\n",
    "            for el in extraction_chain.invoke({\"entities\": entities}).merge_entities\n",
    "        ]\n",
    "        \n",
    "    merged_entities_result = []\n",
    "    merged_future_map = {}\n",
    "    futures = []\n",
    "    merged_failds = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submitting all tasks and creating a list of future objects\n",
    "        for el in potential_duplicate_candidates:\n",
    "            future = executor.submit(entity_resolution, el['combinedResult'])\n",
    "            merged_future_map[future] = el\n",
    "            futures.append(future)\n",
    "        for future in tqdm(\n",
    "            as_completed(futures), total=len(futures), desc=\"Processing documents\"\n",
    "        ):\n",
    "            try:\n",
    "                to_merge = future.result()\n",
    "                if to_merge:\n",
    "                    merged_entities_result.extend(to_merge)\n",
    "            except Exception as e:\n",
    "                el = merged_future_map[future]\n",
    "                print(f'process element faild!:{el['combinedResult']}, error:\\n{e}')\n",
    "                merged_failds.append(el)\n",
    "    if len(merged_failds) > 0 and max_retry > 0:\n",
    "        merged_entities_result.extend(resolve_and_merge_entities_with_llm(merged_failds, max_retry=max_retry-1))\n",
    "    return merged_entities_result\n",
    "merged_entities = resolve_and_merge_entities_with_llm(potential_duplicate_candidates, max_retry=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['投保計劃', '投保計劃別'],\n",
       " ['門診外科手術治療', '門診手術', '門診手術治療'],\n",
       " ['每日住院病房費用保險金限額', '每日住院病房費用保險金限額_2'],\n",
       " ['住院醫療費用保險金限額', '住院醫療費用保險金限額_2'],\n",
       " ['子宮頸未全開', '子宮頸未全開而有臍帶脫落', '子宮頸未全開而有臍帶脫落時'],\n",
       " ['因醫療行為所必要之流產', '醫療行為所必要之流產'],\n",
       " ['嚴重心律不整', '心律不整'],\n",
       " ['胎兒頭皮酸鹼度檢查', '胎兒頭皮酸鹼度檢查Ph值少於7.20'],\n",
       " ['胃靜脈瘤硬化治療', '食道靜脈瘤硬化治療'],\n",
       " ['外科手術費用保險金限額', '外科手術費用保險金限額_2'],\n",
       " ['住院前後門診費用保險金限額', '住院前後門診費用保險金限額_2'],\n",
       " ['補充保險金限額', '補充保險金限額_2'],\n",
       " ['出院後門診腫瘤治療費用保險金限額', '出院後門診腫瘤治療費用保險金限額_2'],\n",
       " ['食道切除再造術', '食道切除術'],\n",
       " ['直線加速器照射治療', '直線加速器照射治療（每次）'],\n",
       " ['照射治療規劃及劑量', '照射治療規劃及劑量（每次）']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "for merge_entity in merged_entities:\n",
    "    merge_entities = [merge_entity]\n",
    "    results = graph.query(\"\"\"\n",
    "  UNWIND $data AS candidates\n",
    "  CALL {\n",
    "    WITH candidates\n",
    "    MATCH (e:__Entity__) WHERE e.id IN candidates\n",
    "    RETURN collect(e) AS nodes, collect(e.sources) AS allSources\n",
    "  }\n",
    "  CALL apoc.refactor.mergeNodes(nodes, {\n",
    "      properties: {\n",
    "        description: 'combine', // 字串會變成陣列\n",
    "        `.*`: 'discard'\n",
    "      }\n",
    "    })\n",
    "  YIELD node\n",
    "  SET node.sources = apoc.coll.toSet(apoc.coll.flatten(allSources))\n",
    "  RETURN count(*)\n",
    "  \"\"\", params={\"data\": merge_entities})\n",
    "    count += results[0]['count(*)']\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
