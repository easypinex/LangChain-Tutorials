{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref: https://medium.com/neo4j/implementing-from-local-to-global-graphrag-with-neo4j-and-langchain-constructing-the-graph-73924cc5bab4\n",
    "### Ref(Github): https://github.com/tomasonjo/blogs/blob/master/llm/ms_graphrag.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"2wsx3edc\"\n",
    "\n",
    "database = os.environ['NEO4J_DATABASE']\n",
    "graph = Neo4jGraph(database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    azure_endpoint='https://lang-chain-dev.openai.azure.com/openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-05-15',\n",
    "    azure_deployment='text-embedding-ada-002',\n",
    "    openai_api_version='2023-05-15'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/pyenv/versions/3.12.5/envs/ACP_LLM_312/lib/python3.12/site-packages/sentence_transformers/models/Dense.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(input_path, \"pytorch_model.bin\"), map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "# ! pip3 install -U langchain-huggingface\n",
    "import os\n",
    "os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/storage/models/embedding_models'\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# Choose from https://huggingface.co/spaces/mteb/leaderboard\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"lier007/xiaobu-embedding-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Neo4jVector.from_existing_graph(\n",
    "    embedding,\n",
    "    node_label='__Entity__',\n",
    "    text_node_properties=['id', 'description'],\n",
    "    embedding_node_property='embedding'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install graphdatascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience \n",
    "\n",
    "gds = GraphDataScience( \n",
    "    os.environ[ \"NEO4J_URI\" ], \n",
    "    auth=(os.environ[ \"NEO4J_USERNAME\" ], os.environ[ \"NEO4J_PASSWORD\" ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graphName                                                         entities\n",
       "database                                                             neo4j\n",
       "databaseLocation                                                     local\n",
       "memoryUsage                                                               \n",
       "sizeInBytes                                                             -1\n",
       "nodeCount                                                               17\n",
       "relationshipCount                                                       46\n",
       "configuration            {'relationshipProjection': {'__ALL__': {'aggre...\n",
       "density                                                           0.169118\n",
       "creationTime                           2024-08-22T08:42:57.278761763+00:00\n",
       "modificationTime                       2024-08-22T08:42:57.345114263+00:00\n",
       "schema                   {'graphProperties': {}, 'nodes': {'__Entity__'...\n",
       "schemaWithOrientation    {'graphProperties': {}, 'nodes': {'__Entity__'...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.graph.drop(\"entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G, result = gds.graph.project(\n",
    "    \"entities\",                   # Graph name\n",
    "    \"__Entity__\",                 # Node projection\n",
    "    \"*\",                          # Relationship projection\n",
    "    nodeProperties=[\"embedding\"]  # Configuration parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ranIterations                                                             2\n",
       "nodePairsConsidered                                                    3345\n",
       "didConverge                                                            True\n",
       "preProcessingMillis                                                       4\n",
       "computeMillis                                                            19\n",
       "mutateMillis                                                             32\n",
       "postProcessingMillis                                                      0\n",
       "nodesCompared                                                            20\n",
       "relationshipsWritten                                                     24\n",
       "similarityDistribution    {'min': 0.9505577087402344, 'p5': 0.9505577087...\n",
       "configuration             {'mutateProperty': 'score', 'jobId': 'afc07559...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_threshold = 0.95\n",
    "\n",
    "gds.knn.mutate(\n",
    "  G,\n",
    "  nodeProperties=['embedding'],\n",
    "  mutateRelationshipType= 'SIMILAR',\n",
    "  mutateProperty= 'score',\n",
    "  similarityCutoff=similarity_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "writeMillis                                                             21\n",
       "nodePropertiesWritten                                                   20\n",
       "componentCount                                                           9\n",
       "componentDistribution    {'min': 1, 'p5': 1, 'max': 10, 'p999': 10, 'p9...\n",
       "postProcessingMillis                                                    17\n",
       "preProcessingMillis                                                      0\n",
       "computeMillis                                                            1\n",
       "configuration            {'writeProperty': 'wcc', 'jobId': 'f05cacdb-aa...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gds.wcc.write(\n",
    "    G,\n",
    "    writeProperty=\"wcc\",\n",
    "    relationshipTypes=[\"SIMILAR\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'combinedResult': ['土地銀行', '第一銀行']}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_edit_distance = 3\n",
    "potential_duplicate_candidates = graph.query(\n",
    "    \"\"\"MATCH (e:`__Entity__`)\n",
    "    WHERE size(e.id) > 3 // longer than 3 characters\n",
    "    WITH e.wcc AS community, collect(e) AS nodes, count(*) AS count\n",
    "    WHERE count > 1\n",
    "    UNWIND nodes AS node\n",
    "    // Add text distance\n",
    "    WITH distinct\n",
    "      [n IN nodes WHERE apoc.text.distance(toLower(node.id), toLower(n.id)) < $distance \n",
    "                  OR node.id CONTAINS n.id | n.id] AS intermediate_results\n",
    "    WHERE size(intermediate_results) > 1\n",
    "    WITH collect(intermediate_results) AS results\n",
    "    // combine groups together if they share elements\n",
    "    UNWIND range(0, size(results)-1, 1) as index\n",
    "    WITH results, index, results[index] as result\n",
    "    WITH apoc.coll.sort(reduce(acc = result, index2 IN range(0, size(results)-1, 1) |\n",
    "            CASE WHEN index <> index2 AND\n",
    "                size(apoc.coll.intersection(acc, results[index2])) > 0\n",
    "                THEN apoc.coll.union(acc, results[index2])\n",
    "                ELSE acc\n",
    "            END\n",
    "    )) as combinedResult\n",
    "    WITH distinct(combinedResult) as combinedResult\n",
    "    // extra filtering\n",
    "    WITH collect(combinedResult) as allCombinedResults\n",
    "    UNWIND range(0, size(allCombinedResults)-1, 1) as combinedResultIndex\n",
    "    WITH allCombinedResults[combinedResultIndex] as combinedResult, combinedResultIndex, allCombinedResults\n",
    "    WHERE NOT any(x IN range(0,size(allCombinedResults)-1,1)\n",
    "        WHERE x <> combinedResultIndex\n",
    "        AND apoc.coll.containsAll(allCombinedResults[x], combinedResult)\n",
    "    )\n",
    "    RETURN combinedResult\n",
    "    \"\"\", params={'distance': word_edit_distance})\n",
    "potential_duplicate_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/miniforge3/envs/lagch/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `OllamaFunctions` was deprecated in LangChain 0.0.64 and will be removed in 0.4.0. An updated version of the class exists in the langchain-ollama package and should be used instead. To use it run `pip install -U langchain-ollama` and import as `from langchain_ollama import ChatOllama`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OllamaFunctions(model='qwen2:72b-instruct-q8_0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "model_name = 'qwen2:72b-instruct-q8_0'\n",
    "llm = OllamaFunctions(model=model_name)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"You are a data processing assistant. Your task is to identify duplicate entities in a list and decide which of them should be merged.\n",
    "The entities might be slightly different in format or content, but essentially refer to the same thing. Use your analytical skills to determine duplicates.\n",
    "\n",
    "Here are the rules for identifying duplicates:\n",
    "1. Entities with minor typographical differences should be considered duplicates.\n",
    "2. Entities with different formats but the same content should be considered duplicates.\n",
    "3. Entities that refer to the same real-world object or concept, even if described differently, should be considered duplicates.\n",
    "4. If it refers to different numbers, dates, or products, do not merge results\n",
    "\"\"\"\n",
    "user_template = \"\"\"\n",
    "Here is the list of entities to process:\n",
    "{entities}\n",
    "\n",
    "Please identify duplicates, merge them, and provide the merged list.\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class DuplicateEntities(BaseModel):\n",
    "    entities: List[str] = Field(\n",
    "        description=\"Entities that represent the same object or real-world entity and should be merged\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Disambiguate(BaseModel):\n",
    "    merge_entities: Optional[List[DuplicateEntities]] = Field(\n",
    "        description=\"Lists of entities that represent the same object or real-world entity and should be merged\"\n",
    "    )\n",
    "\n",
    "\n",
    "extraction_llm = llm.with_structured_output(\n",
    "    Disambiguate\n",
    ")\n",
    "\n",
    "extraction_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            user_template,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = extraction_prompt | extraction_llm\n",
    "\n",
    "def entity_resolution(entities: List[str]) -> Optional[List[List[str]]]:\n",
    "    return [\n",
    "        el.entities\n",
    "        for el in extraction_chain.invoke({\"entities\": entities}).merge_entities\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "merged_entities = []\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    # Submitting all tasks and creating a list of future objects\n",
    "    futures = [\n",
    "        executor.submit(entity_resolution, el['combinedResult'])\n",
    "        for el in potential_duplicate_candidates\n",
    "    ]\n",
    "\n",
    "    for future in tqdm(\n",
    "        as_completed(futures), total=len(futures), desc=\"Processing documents\"\n",
    "    ):\n",
    "        try:\n",
    "            to_merge = future.result()\n",
    "            if to_merge:\n",
    "                merged_entities.extend(to_merge)\n",
    "        except Exception as e:\n",
    "            print('error processing document', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count(*)': 0}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"\"\"\n",
    "UNWIND $data AS candidates\n",
    "CALL {\n",
    "  WITH candidates\n",
    "  MATCH (e:__Entity__) WHERE e.id IN candidates\n",
    "  RETURN collect(e) AS nodes\n",
    "}\n",
    "CALL apoc.refactor.mergeNodes(nodes, {\n",
    "    properties: {\n",
    "      `.*`: 'discard'\n",
    "    }\n",
    "  })\n",
    "YIELD node\n",
    "RETURN count(*)\n",
    "\"\"\", params={\"data\": merged_entities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
