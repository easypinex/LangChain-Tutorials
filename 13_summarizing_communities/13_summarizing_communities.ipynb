{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"2wsx3edc\"\n",
    "\n",
    "database = os.environ.get('NEO4J_DATABASE')\n",
    "graph = Neo4jGraph(database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience \n",
    "\n",
    "gds = GraphDataScience( \n",
    "    os.environ[ \"NEO4J_URI\" ], \n",
    "    auth=(os.environ[ \"NEO4J_USERNAME\" ], os.environ[ \"NEO4J_PASSWORD\" ]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.graph.drop(\"communities\")\n",
    "G, result = gds.graph.project(\n",
    "    \"communities\",  #  Graph name\n",
    "    \"__Entity__\",  #  Node projection\n",
    "    {\n",
    "        \"_ALL_\": {\n",
    "            \"type\": \"*\",\n",
    "            \"orientation\": \"UNDIRECTED\",\n",
    "            \"properties\": {\"weight\": {\"property\": \"*\", \"aggregation\": \"COUNT\"}},\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcc = gds.wcc.stats(G)\n",
    "print(f\"Component count: {wcc['componentCount']}\")\n",
    "print(f\"Component distribution: {wcc['componentDistribution']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds.leiden.write(\n",
    "    G,\n",
    "    writeProperty=\"communities\",\n",
    "    includeIntermediateCommunities=True,\n",
    "    relationshipWeightProperty=\"weight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "MATCH (e:`__Entity__`)\n",
    "UNWIND range(0, size(e.communities) - 1 , 1) AS index\n",
    "CALL {\n",
    "  WITH e, index\n",
    "  WITH e, index\n",
    "  WHERE index = 0\n",
    "  MERGE (c:`__Community__` {id: toString(index) + '-' + toString(e.communities[index])})\n",
    "  ON CREATE SET c.level = index\n",
    "  MERGE (e)-[:IN_COMMUNITY]->(c)\n",
    "  RETURN count(*) AS count_0\n",
    "}\n",
    "CALL {\n",
    "  WITH e, index\n",
    "  WITH e, index\n",
    "  WHERE index > 0\n",
    "  MERGE (current:`__Community__` {id: toString(index) + '-' + toString(e.communities[index])})\n",
    "  ON CREATE SET current.level = index\n",
    "  MERGE (previous:`__Community__` {id: toString(index - 1) + '-' + toString(e.communities[index - 1])})\n",
    "  ON CREATE SET previous.level = index - 1\n",
    "  MERGE (previous)-[:IN_COMMUNITY]->(current)\n",
    "  RETURN count(*) AS count_1\n",
    "}\n",
    "RETURN count(*)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "MATCH (c:__Community__)<-[:IN_COMMUNITY*]-(:__Entity__)<-[:HAS_ENTITY]-(d:__Chunk__)\n",
    "WITH c, count(distinct d) AS rank\n",
    "SET c.rank = rank;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "community_size = graph.query(\n",
    "    \"\"\"\n",
    "MATCH (c:__Community__)<-[:IN_COMMUNITY*]-(e:__Entity__)\n",
    "WITH c, count(distinct e) AS entities\n",
    "RETURN split(c.id, '-')[0] AS level, entities\n",
    "\"\"\"\n",
    ")\n",
    "community_size_df = pd.DataFrame.from_records(community_size)\n",
    "percentiles_data = []\n",
    "for level in community_size_df[\"level\"].unique():\n",
    "    subset = community_size_df[community_size_df[\"level\"] == level][\"entities\"]\n",
    "    num_communities = len(subset)\n",
    "    percentiles = np.percentile(subset, [25, 50, 75, 90, 99])\n",
    "    percentiles_data.append(\n",
    "        [\n",
    "            level,\n",
    "            num_communities,\n",
    "            percentiles[0],\n",
    "            percentiles[1],\n",
    "            percentiles[2],\n",
    "            percentiles[3],\n",
    "            percentiles[4],\n",
    "            max(subset)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Create a DataFrame with the percentiles\n",
    "percentiles_df = pd.DataFrame(\n",
    "    percentiles_data,\n",
    "    columns=[\n",
    "        \"Level\",\n",
    "        \"Number of communities\",\n",
    "        \"25th Percentile\",\n",
    "        \"50th Percentile\",\n",
    "        \"75th Percentile\",\n",
    "        \"90th Percentile\",\n",
    "        \"99th Percentile\",\n",
    "        \"Max\"\n",
    "    ],\n",
    ")\n",
    "percentiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_info = graph.query(\"\"\"\n",
    "MATCH (c:`__Community__`)<-[:IN_COMMUNITY*]-(e:__Entity__)\n",
    "WHERE c.level IN [0,1,4]\n",
    "WITH c, collect(e ) AS nodes\n",
    "WHERE size(nodes) > 1\n",
    "CALL apoc.path.subgraphAll(nodes[0], {\n",
    " whitelistNodes:nodes\n",
    "})\n",
    "YIELD relationships\n",
    "RETURN c.id AS communityId, \n",
    "       [n in nodes | {id: n.id, description: n.description, type: [el in labels(n) WHERE el <> '__Entity__'][0]}] AS nodes,\n",
    "       [r in relationships | {start: startNode(r).id, type: type(r), end: endNode(r).id, description: r.description}] AS rels\n",
    "\"\"\")\n",
    "community_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "# model_name = 'qwen2:72b-instruct-q8_0'\n",
    "# llm = OllamaFunctions(model=model_name, temperature=0)\n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "community_template = \"\"\"請根據提供同社區的資訊包含 nodes 與 relationships,\n",
    "產生自然語言的摘要 同社區的資訊\n",
    "請確保使用繁體中文回應:\n",
    "{community_info}\n",
    "\n",
    "Summary:\"\"\"  # noqa: E501\n",
    "\n",
    "community_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input triples, generate the information summary. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", community_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "community_chain = community_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_string(data):\n",
    "    nodes_str = \"Nodes are:\\n\"\n",
    "    for node in data['nodes']:\n",
    "        node_id = node['id']\n",
    "        node_type = node['type']\n",
    "        if 'description' in node and node['description']:\n",
    "            node_description = f\", description: {node['description']}\"\n",
    "        else:\n",
    "            node_description = \"\"\n",
    "        nodes_str += f\"id: {node_id}, type: {node_type}{node_description}\\n\"\n",
    "\n",
    "    rels_str = \"Relationships are:\\n\"\n",
    "    for rel in data['rels']:\n",
    "        start = rel['start']\n",
    "        end = rel['end']\n",
    "        rel_type = rel['type']\n",
    "        if 'description' in rel and rel['description']:\n",
    "            description = f\", description: {rel['description']}\"\n",
    "        else:\n",
    "            description = \"\"\n",
    "        rels_str += f\"({start})-[:{rel_type}]->({end}){description}\\n\"\n",
    "\n",
    "    return nodes_str + \"\\n\" + rels_str\n",
    "\n",
    "def process_community(community):\n",
    "    stringify_info = prepare_string(community)\n",
    "    summary = community_chain.invoke({'community_info': stringify_info})\n",
    "    return {\"community\": community['communityId'], \"summary\": summary}\n",
    "\n",
    "# process_community(community_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_community_with_llm(community_info, max_retry=0):\n",
    "    '''\n",
    "    params:\n",
    "        community_info: [ { \n",
    "                            'communityId': str, 'nodes': [{'id': str, 'description': str|None, 'type': str}, ...], \n",
    "                            'rels': [{'start': str, 'description': str|None, 'type': str, 'end': 'str}, ...]\n",
    "                          },\n",
    "                          ... ]\n",
    "        max_retry: 最多嘗試次數, 假設為2, 則最多遞迴執行 2+1=3次\n",
    "    '''\n",
    "    summaries = []\n",
    "    faild_communities = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = {executor.submit(process_community, community): community for community in community_info}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing communities\"):\n",
    "            try:\n",
    "                summaries.append(future.result())\n",
    "            except Exception as e:\n",
    "                community = futures[future]\n",
    "                print(f'process community faild!:{community}, error:\\n{e}')\n",
    "                faild_communities.append(community)\n",
    "    if len(faild_communities) > 0 and max_retry > 0:\n",
    "        summaries.extend(process_community_with_llm(faild_communities, max_retry=max_retry-1))\n",
    "    return summaries\n",
    "summaries = process_community_with_llm(community_info, max_retry=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "UNWIND $data AS row\n",
    "MERGE (c:__Community__ {id:row.community})\n",
    "SET c.summary = row.summary\n",
    "\"\"\", params={\"data\": summaries})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
